{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "8K4iARDu-PxB",
        "outputId": "dfed4527-0d43-4c52-9211-40bce7f28ccf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid character '’' (U+2019) (<ipython-input-1-16a3945a8747>, line 4)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-16a3945a8747>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    A company’s financial reports stored in an Excel file. - Structured because there is a predefined structure within Excel.\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '’' (U+2019)\n"
          ]
        }
      ],
      "source": [
        "Exercise #1\n",
        "Below are various data sources. Identify whether each one is an example of structured or unstructured data.\n",
        "\n",
        "A company’s financial reports stored in an Excel file. - Structured because there is a predefined structure within Excel.\n",
        "Photographs uploaded to a social media platform. - Unstructured because there is no predefined structure.\n",
        "A collection of news articles on a website. - Unstructured because there is no predefined structure.\n",
        "Inventory data in a relational database. - Structured because there is a predefined structure within a database.\n",
        "Recorded interviews from a market research study.  - Unstructured because there is no predefined structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BTAqAg_Vrnan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Exercise 2: Transformation Exercise\n",
        "For each of the following unstructured data sources, propose a method to convert it into structured data. Explain your reasoning.\n",
        "\n",
        "1) A series of blog posts about travel experiences.\n",
        "a) Find the key information regarding the blog posts, so the data could be in a datadase such as, duration of the stay, trip location, date of travel etc...\n",
        "\n",
        "2) Audio recordings of customer service calls.\n",
        "a) Find the key information regarding the customer service calls, The data can be transcribed from voice to text  and categorized from there. It can be categorized by call duration, customer satifaction level and if the problem was resolved or not.\n",
        "\n",
        "3) Handwritten notes from a brainstorming session.\n",
        "a) Use computer vision to convert the handwritten notes into digital texts, and then from there categorizing it based on different topics.\n",
        "\n",
        "4) A video tutorial on cooking.\n",
        "a) Find the key information about the video tutorials on cooking. The key information would be video duration, recipes used, difficultiy of the dish, etc...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "fJfIgLz-_a-m",
        "outputId": "cc0fcaf9-587a-4345-b920-92847d2c1f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-2-95549c84ff20>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-95549c84ff20>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Exercise 2: Transformation Exercise\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " Exercise 3 : Application Scenario\n",
        "Instructions\n",
        "Q: You are a data analyst at a retail company. You have access to various data sources, including transaction records, customer feedback comments, social media posts about your brand, and employee work schedules.\n",
        "\n",
        "Categorize each of these data sources as structured or unstructured.\n",
        "Suggest how you might use each type of data for improving the company’s business operations.\n",
        "\n",
        "A: If I am a data analyst with those information it would be important to categorize them to be either structured or unstructured. It would be important to note if it's unstrucutred data because that will imply that tools like NoSQL and MongoDB will be needed and if it's given that there is a strcutured database then relational databases like SQL will be needed to be used.\n",
        "\n"
      ],
      "metadata": {
        "id": "Y6P88JC5CHyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise 4\n",
        "from faker import Faker\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "fake = Faker()\n",
        "names = [fake.name() for _ in range(100)]\n",
        "addresses = [fake.address().replace('\\n', ', ') for i in range(100)]\n",
        "emails = [fake.email() for i in range(100)]\n",
        "\n",
        "ages = np.random.randint(20, 61, 100)\n",
        "\n",
        "# Generate random income levels (let's say between $20,000 and $150,000)\n",
        "incomes = np.random.randint(20000, 150001, 100)\n",
        "\n",
        "# Combine data into a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Name': names,\n",
        "    'Address': addresses,\n",
        "    'Email': emails,\n",
        "    'Age': ages,\n",
        "    'Income': incomes\n",
        "})\n",
        "\n",
        "# Display the first 10 rows of the DataFrame\n",
        "print(df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVYOV2o0DTwN",
        "outputId": "36c55450-dbb4-4ab2-a746-e6172aafe2f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Name                                            Address  \\\n",
            "0    Travis Buchanan                           USNV Smith, FPO AE 38704   \n",
            "1     Collin Jackson        1871 Derek Drive, Lake Juliemouth, KS 30271   \n",
            "2         Eric Lopez          2933 Evans River, Stokeschester, PR 80210   \n",
            "3  Angela Montgomery  79101 Mark Mount Suite 171, East Andrea, VI 02400   \n",
            "4      Wendy Maxwell  3791 Moreno Trace Suite 185, Bobbychester, MH ...   \n",
            "5     Tamara Simpson             45253 Nolan Loop, Jamesmouth, IN 44431   \n",
            "6      Larry Shannon  53771 Faulkner Wells Apt. 803, Barryberg, OK 3...   \n",
            "7     Denise Bennett                   Unit 8693 Box 5251, DPO AE 56309   \n",
            "8      Michael Gates  1346 Daniel Harbor Apt. 258, Gonzalezshire, MP...   \n",
            "9         Jack Davis                 641 King Rue, West Lucas, ID 23054   \n",
            "\n",
            "                       Email  Age  Income  \n",
            "0    ellisjoshua@example.net   28  112955  \n",
            "1   holmesshelly@example.org   43   69096  \n",
            "2   fisherandrea@example.net   37  105529  \n",
            "3        rforbes@example.net   31  128746  \n",
            "4  murrayrichard@example.net   43   98717  \n",
            "5     oscarperez@example.com   59  112965  \n",
            "6     wendyglass@example.org   49   61783  \n",
            "7        cjensen@example.net   44   77274  \n",
            "8  piercelindsey@example.com   42   79076  \n",
            "9       ldaniels@example.com   40  122419  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opendatasets\n",
        "pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "uK1766Q5EBI2",
        "outputId": "be4712ae-fae5-4650-ea17-9d5d4a347e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-4-f96c529b16a3>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-f96c529b16a3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install opendatasets\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#Exerise 5: Dog Augmentation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "#import opendatasets as od\n",
        "import pandas as pd\n",
        "\n",
        "! pip install -q kaggle\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle datasets download -d yaswanthgali/dog-images\n",
        "\n",
        "!unzip dog-images.zip\n",
        "\n",
        "\n",
        "\n",
        "data_generator = ImageDataGenerator(rotation_range=30)\n",
        "\n",
        "\n",
        "from scipy.ndimage import rotate\n",
        "def rotate_image_30_degrees(image):\n",
        "# Rotate image by 30 degrees\n",
        "  return rotate(image, 30, reshape=False, mode='nearest')\n",
        "#  Create ImageDataGenerator with custom preprocessing function\n",
        "data_generator = ImageDataGenerator(preprocessing_function=rotate_image_30_degrees)\n",
        "\n",
        "\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation\n",
        "data_generator = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    brightness_range=(0.5, 1.5)\n",
        ")\n",
        "\n",
        "# Assuming 'images_directory' is the path to your dataset of dog images\n",
        "# This code will augment images and save them in 'augmented_images_directory'\n",
        "augmented_images_directory = '/content/images/images'\n",
        "data_generator.flow_from_directory('/content/images/images', save_to_dir='/content/augmented_images')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "original = '/content/images/images'\n",
        "augmented = '/content/augmented_images'\n",
        "# Create an instance of the ImageDataGenerator with desired augmentations\n",
        "data_generator = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    brightness_range=[0.5, 1.5]\n",
        ")\n",
        "for filename in os.listdir(original):\n",
        "    # Load the image\n",
        "    img = load_img(os.path.join(original, filename, filename))\n",
        "    x = img_to_array(img)\n",
        "    x = x.reshape((1,) + x.shape)\n",
        "    # Generate augmented images\n",
        "    i = 0\n",
        "    for batch in data_generator.flow(x, batch_size=1, save_to_dir=augmented, save_prefix='aug', save_format='jpeg'):\n",
        "        i += 1\n",
        "        if i > 4:  # Generate 4 augmented images for each original image\n",
        "            break"
      ],
      "metadata": {
        "id": "Bybo-SDvsdJD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "b49f2533-b6da-4a01-97bd-aee24f8b8b13"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'opendatasets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2978eb3d72db>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopendatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'opendatasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Tzvh7R_V-Rcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise 6\n",
        "Exercise 6 : Simulation-Based Dataset Creation\n",
        "Instructions\n",
        "Imagine you are developing a simulation for traffic flow in a city. Your goal is to generate a dataset that reflects different traffic conditions at various times of the day.\n",
        "Outline the steps you would take to create this simulation. Consider factors like vehicle types, road types, traffic signals, and peak/off-peak hours.\n",
        "Describe how you would collect data from this simulation, specifying the types of data (e.g., vehicle count, average speed) you would gather at different time intervals.\n",
        "Discuss the potential uses of this simulated dataset in traffic management and urban planning.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Collection would be through observational data like calculating the vehicle count, average vehicle speed, travel time, intersection delay, etc..."
      ],
      "metadata": {
        "id": "Q0FKjm2drtDq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "760ff9de-e3f9-4e44-9fc0-f55705d08f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-10-17cd8de5c8f1>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-17cd8de5c8f1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    A way to create a simulation dataset would be to create a virtual city map with a variety of road type  and different car types.  It would be ideal to find historical datasets which account for peak  and off peak hours.\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n1IUJLtTq54m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}